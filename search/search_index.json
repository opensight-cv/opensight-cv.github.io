{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"OpenSight: the powerful, easy-to-use vision suite \u00b6 OpenSight is an FRC-focused, free and open source computer vision system targeted specifically for the Raspberry Pi. Our goal is to make it easy for people not familiar with vision to be able to make complex pipelines, while also providing powerful functionality for advanced users. Click here for information on how to install OpenSight! \u00b6 About \u00b6 Our mission is to create an accessible vision suite, with an easy-to-use and works out-of-the box experience, but also allow for more power and greater customizability. We want to make vision more accessible to those with less experience, while also providing the tools for power users and developers to easily add features beyond the default modules. Have any questions, comments, or want to contribute? \u00b6 You can learn more about contributing here ! TL;DR: Join the OpenSight Discord server and we'll get you set up!","title":"Home"},{"location":"#opensight-the-powerful-easy-to-use-vision-suite","text":"OpenSight is an FRC-focused, free and open source computer vision system targeted specifically for the Raspberry Pi. Our goal is to make it easy for people not familiar with vision to be able to make complex pipelines, while also providing powerful functionality for advanced users.","title":"OpenSight: the powerful, easy-to-use vision suite"},{"location":"#click-here-for-information-on-how-to-install-opensight","text":"","title":"Click here for information on how to install OpenSight!"},{"location":"#about","text":"Our mission is to create an accessible vision suite, with an easy-to-use and works out-of-the box experience, but also allow for more power and greater customizability. We want to make vision more accessible to those with less experience, while also providing the tools for power users and developers to easily add features beyond the default modules.","title":"About"},{"location":"#have-any-questions-comments-or-want-to-contribute","text":"You can learn more about contributing here ! TL;DR: Join the OpenSight Discord server and we'll get you set up!","title":"Have any questions, comments, or want to contribute?"},{"location":"planned/","text":"Planned pages \u00b6 Modules: Contours: modules/contours.md Video IO: modules/videoio.md Color Operations: modules/color.md Mask Operations: modules/mask.md Drawing Operations: modules/draw.md NetworkTables: modules/nt.md","title":"Planned Pages"},{"location":"planned/#planned-pages","text":"Modules: Contours: modules/contours.md Video IO: modules/videoio.md Color Operations: modules/color.md Mask Operations: modules/mask.md Drawing Operations: modules/draw.md NetworkTables: modules/nt.md","title":"Planned pages"},{"location":"roadmap/","text":"OpenSight is still very much an active project. You can see our Trello board for a full list of everything we plan to do in the near future. Here's some of the highlights: Contour Filtering functions (such as area, aspect ratio, fullness, count) Static IP networking settings H.264 CameraServer with Shuffleboard plugin Basic conditional logic functions GPIO control module If you would like to help out with any of these features or you have any feedback whatsoever, please join our Discord ! We would love to hear your feedback in the #feedback channel. If you are interested in contributing, say so and any preference as to what to work on in #general and we will get you set up as soon as possible.","title":"Roadmap and Contributing"},{"location":"module-dev/glossary/","text":"Glossary \u00b6 Work in progress. \u00b6 This page contains a list of the words you may seen used in these documents or in disucssion. Module A directory or single Python file which supplies OpenSight with Functions.","title":"Glossary"},{"location":"module-dev/glossary/#glossary","text":"","title":"Glossary"},{"location":"module-dev/glossary/#work-in-progress","text":"This page contains a list of the words you may seen used in these documents or in disucssion. Module A directory or single Python file which supplies OpenSight with Functions.","title":"Work in progress."},{"location":"module-dev/intro/","text":"Creating Modules \u00b6 Modules make up a great portion of OpenSight's functionality. They are special types of classes that can operate on inputs and give outputs. They can be used in a wide variety of ways, such as modifing an image, performing math operations, or communicating with a server. Here's an example module, which does the following: Has a setting for the radius of the blur (of type integer) Inputs an image (of type Mat) Outputs the blurred image from dataclasses import dataclass import opsi.manager.cvwrapper as cvw from opsi.manager.manager_schema import Function from opsi.manager.types import Mat , MatBW __package__ = \"opsi.example_module\" __version__ = \"0.123\" class Blur ( Function ): @dataclass class Settings : radius : int @dataclass class Inputs : img : Mat @dataclass class Outputs : img : Mat def run ( self , inputs ): img = cvw . blur ( inputs . img , self . settings . radius ) return self . Outputs ( img = img ) There are already many useful modules included in OpenSight, but creating your own can add more complexity to your vision pipeline. The source code for the modules is located under opsi/modules in the OpenSight repo. Warning Using the cv2 library directly is discouraged. All new OpenCV functionality should go into cvwrapper.py .","title":"Introduction"},{"location":"module-dev/intro/#creating-modules","text":"Modules make up a great portion of OpenSight's functionality. They are special types of classes that can operate on inputs and give outputs. They can be used in a wide variety of ways, such as modifing an image, performing math operations, or communicating with a server. Here's an example module, which does the following: Has a setting for the radius of the blur (of type integer) Inputs an image (of type Mat) Outputs the blurred image from dataclasses import dataclass import opsi.manager.cvwrapper as cvw from opsi.manager.manager_schema import Function from opsi.manager.types import Mat , MatBW __package__ = \"opsi.example_module\" __version__ = \"0.123\" class Blur ( Function ): @dataclass class Settings : radius : int @dataclass class Inputs : img : Mat @dataclass class Outputs : img : Mat def run ( self , inputs ): img = cvw . blur ( inputs . img , self . settings . radius ) return self . Outputs ( img = img ) There are already many useful modules included in OpenSight, but creating your own can add more complexity to your vision pipeline. The source code for the modules is located under opsi/modules in the OpenSight repo. Warning Using the cv2 library directly is discouraged. All new OpenCV functionality should go into cvwrapper.py .","title":"Creating Modules"},{"location":"module-dev/structure/","text":"Module Structure \u00b6 Modules \u00b6 TODO: explain module package structure Functions (break into separate file?) \u00b6 TODO: explain general class setup A function has three main user-facing components: Inputs , Outputs , and Settings . Each one of these is a statically defined Python dataclass . You can create a dataclass by creating a class with the @dataclass decorator, as shown here: @dataclass class Inputs : x : int","title":"Module Structure"},{"location":"module-dev/structure/#module-structure","text":"","title":"Module Structure"},{"location":"module-dev/structure/#modules","text":"TODO: explain module package structure","title":"Modules"},{"location":"module-dev/structure/#functions-break-into-separate-file","text":"TODO: explain general class setup A function has three main user-facing components: Inputs , Outputs , and Settings . Each one of these is a statically defined Python dataclass . You can create a dataclass by creating a class with the @dataclass decorator, as shown here: @dataclass class Inputs : x : int","title":"Functions (break into separate file?)"},{"location":"modules/color/","text":"TODO","title":"Color"},{"location":"modules/contours/","text":"TODO","title":"Contours"},{"location":"modules/draw/","text":"TODO","title":"Draw"},{"location":"modules/mask/","text":"TODO","title":"Mask"},{"location":"modules/nt/","text":"TODO","title":"Nt"},{"location":"modules/videoio/","text":"TODO","title":"Videoio"},{"location":"quickstart/getting-started/","text":"Once you have OpenSight installed, you need to access your Raspberry Pi to view the interface. The way to accomplish this will vary based on your setup. If you are on a robot network, simply go to http://opensight.local/ in your browser. Note Currently there is no mechanism for static IPs, however this is a planned feature for the next minor update. Nodetree Interface \u00b6 The nodetree interface is the heart of OpenSight. Here you will see everything you need in order to create a working vision pipeline. Each draggable block is called a \" node \". Every node an instance of a certain \" function \", which defines what it does. For example, seen below is a node with the blur function. Each node has inputs and outputs . You can drag the output of any node into any input of the same type. Each input and output has a name which should give you a good idea what it can connect to. For example, the blur node above inputs any image and also outputs an image. Many nodes have settings . These are options which affect what the function of a node actually does. For example, the radius setting in the blur node affects how strongly the input image should be blurred. Node Menu \u00b6 Different functions are broken up into different modules . Each module is displayed separately in the node menu. Similar nodes are grouped together in modules. For example, nodes pertaining to NetworkTables are kept in opsi-nt, and nodes pertaining to contours can be found in opsi-contours. You can click on a button to create a node of that name. Status Indicator \u00b6 The status indicator is at the bottom right of the nodetree interface. Here, you can see the status of your nodetree. If it has saved and started to run successfully, you will see a green checkmark. If there is an error, an X will be displayed. You can hover over this X to see the error. After modifying the nodetree, the status indicator will turn gray and then run a spinning animation while it is being saved and tested. Settings \u00b6 The settings menu is where the system configuration is located, as compared to node-level configuration. Network Config \u00b6 Static IP Currently, this indicates whether your roboRIO network uses a static IP system (eg. access your roboRIO at 10.TE.AM.2). A proper static IP setting mechanism is planned for update v0.2.0. Server Mode If you aren't on a roboRIO network and want to access NetworkTables, you can enable \"Server\" mode. In Shuffleboard settings you can set the \"Server\" to the IP of your OpenSight instance (eg. opensight.local). If you are on a roboRIO network, this should always be \"Client\". Note Some options, such as system restart options and the updater are only available on the Raspberry Pi or other ARM systems. Viewing the Camera Stream \u00b6 You can view the Camera Stream through a part in OpenSight known as a \"Hook\". Each module can have its own hook. A hook is webpage which allows a module or node to be viewable in some way. Camera Server uses a hook which allows you to view the stream of every camera server by clicking the opsi.videio hook. NetworkTables will also have its own hook soon.","title":"Getting Started"},{"location":"quickstart/getting-started/#nodetree-interface","text":"The nodetree interface is the heart of OpenSight. Here you will see everything you need in order to create a working vision pipeline. Each draggable block is called a \" node \". Every node an instance of a certain \" function \", which defines what it does. For example, seen below is a node with the blur function. Each node has inputs and outputs . You can drag the output of any node into any input of the same type. Each input and output has a name which should give you a good idea what it can connect to. For example, the blur node above inputs any image and also outputs an image. Many nodes have settings . These are options which affect what the function of a node actually does. For example, the radius setting in the blur node affects how strongly the input image should be blurred.","title":"Nodetree Interface"},{"location":"quickstart/getting-started/#node-menu","text":"Different functions are broken up into different modules . Each module is displayed separately in the node menu. Similar nodes are grouped together in modules. For example, nodes pertaining to NetworkTables are kept in opsi-nt, and nodes pertaining to contours can be found in opsi-contours. You can click on a button to create a node of that name.","title":"Node Menu"},{"location":"quickstart/getting-started/#status-indicator","text":"The status indicator is at the bottom right of the nodetree interface. Here, you can see the status of your nodetree. If it has saved and started to run successfully, you will see a green checkmark. If there is an error, an X will be displayed. You can hover over this X to see the error. After modifying the nodetree, the status indicator will turn gray and then run a spinning animation while it is being saved and tested.","title":"Status Indicator"},{"location":"quickstart/getting-started/#settings","text":"The settings menu is where the system configuration is located, as compared to node-level configuration.","title":"Settings"},{"location":"quickstart/getting-started/#network-config","text":"Static IP Currently, this indicates whether your roboRIO network uses a static IP system (eg. access your roboRIO at 10.TE.AM.2). A proper static IP setting mechanism is planned for update v0.2.0. Server Mode If you aren't on a roboRIO network and want to access NetworkTables, you can enable \"Server\" mode. In Shuffleboard settings you can set the \"Server\" to the IP of your OpenSight instance (eg. opensight.local). If you are on a roboRIO network, this should always be \"Client\". Note Some options, such as system restart options and the updater are only available on the Raspberry Pi or other ARM systems.","title":"Network Config"},{"location":"quickstart/getting-started/#viewing-the-camera-stream","text":"You can view the Camera Stream through a part in OpenSight known as a \"Hook\". Each module can have its own hook. A hook is webpage which allows a module or node to be viewable in some way. Camera Server uses a hook which allows you to view the stream of every camera server by clicking the opsi.videio hook. NetworkTables will also have its own hook soon.","title":"Viewing the Camera Stream"},{"location":"quickstart/hardware/","text":"OpenSight primarily targets the Raspberry Pi, however, it can be run on numerous different setups. OpenSight supports all cameras. If you have any compatibility issues with any coprocessor or camera, come to our Discord . Hardware Configurations \u00b6 The Raspberry Pi (and other coprocessors, such as the Jetson Nano) require 5V, so if you are using OpenSight on a robot, you will need to step down from 12V to 5V. All configurations include an appropriate step down module. Here are some recommended configurations at different price points. Each configuration inculdes a either typical or estimated performance. Any configurations with an estimated performance will be marked with a *. If you have any of these configurations and want to submit performance figures, we would greatly appreciate it! Most product links are Amazon links for consistency, however many of these parts can be found cheaper from their manufactuer or other websites. Warning Please note that we have not tested all of these items. We are not specifically recommending any of these products. We are not liable for any non-working configurations or for any damage you do to any components. OscarEye \u00b6 Raspberry Pi 4 85 FPS @ 320x240 \u00b6 Item Link Price Raspberry Pi 4 (1GB RAM) https://amazon.com/dp/B07TD43PDZ $41.99 Raspberry Pi 4 Case https://amazon.com/dp/B07W3ZMVP1 $8.99 Arducam 5 https://amazon.com/dp/B012V1HEP4 $12.99 16GB MicroSD Card https://amazon.com/dp/B073K14CVB $5.79 HOMREE DC 12V to DC 5V (USB-C) https://amazon.com/dp/B07ZQB6S3L $10.90 Total $80.66 NVIDIA Jetson Nano 120+ FPS @ 320x240 * \u00b6 Item Link Price NVIDIA Jetson Nano Development Kit https://amazon.com/dp/B07PZHBDKT $98.95 Arducam 5* https://amazon.com/dp/B012V1HEP4 $12.99 16GB MicroSD Card https://amazon.com/dp/B073K14CVB $5.79 HOMREE DC 12V to DC 5V (Micro USB) https://amazon.com/dp/B01MEESLZ6 $9.99 Total $127.72 * Yes, cameras for Raspberry Pi work on the Jetson Nano General Setup \u00b6 To connect any coprocessor to the robot, you will need an Ethernet cable . Plug the Ethernet cable into the extra port on the radio to connect your coprocessor to the robot. Using a Pi Cam \u00b6 If you are using a Pi Cam (such as the Arducam 5) you will need to connect your Pi Cam to the port boxed in PURPLE on the image. Do not connect it to the port boxed in BLUE on the image. LEDs \u00b6 You can control LEDs either directly from the robot using the PCM, or by using GPIO (GPIO module coming soon). PCM \u00b6 If you want to use PCM, make sure your PCM is running 12V, not 24V . Once you plug your LEDs into the PCM, you can control them from the Robot Code in the same way you would control a regular solenoid ( Java / C++ ). GPIO \u00b6 If you plan on using GPIO, you will need a relay switch of some sort. Keep in mind that the Raspberry Pi's GPIO only outputs 3.3V. Here is a relay switch which has been successfully tested with a Raspberry Pi 4. Also, most LEDs run off of 12V. Here is a diagram of how to properly set up LED control from the Pi. Here is a diagram of how to properly set this up:","title":"Hardware"},{"location":"quickstart/hardware/#hardware-configurations","text":"The Raspberry Pi (and other coprocessors, such as the Jetson Nano) require 5V, so if you are using OpenSight on a robot, you will need to step down from 12V to 5V. All configurations include an appropriate step down module. Here are some recommended configurations at different price points. Each configuration inculdes a either typical or estimated performance. Any configurations with an estimated performance will be marked with a *. If you have any of these configurations and want to submit performance figures, we would greatly appreciate it! Most product links are Amazon links for consistency, however many of these parts can be found cheaper from their manufactuer or other websites. Warning Please note that we have not tested all of these items. We are not specifically recommending any of these products. We are not liable for any non-working configurations or for any damage you do to any components.","title":"Hardware Configurations"},{"location":"quickstart/hardware/#oscareye","text":"","title":"OscarEye"},{"location":"quickstart/hardware/#raspberry-pi-4-85-fps-320x240","text":"Item Link Price Raspberry Pi 4 (1GB RAM) https://amazon.com/dp/B07TD43PDZ $41.99 Raspberry Pi 4 Case https://amazon.com/dp/B07W3ZMVP1 $8.99 Arducam 5 https://amazon.com/dp/B012V1HEP4 $12.99 16GB MicroSD Card https://amazon.com/dp/B073K14CVB $5.79 HOMREE DC 12V to DC 5V (USB-C) https://amazon.com/dp/B07ZQB6S3L $10.90 Total $80.66","title":"Raspberry Pi 4 85 FPS @ 320x240"},{"location":"quickstart/hardware/#nvidia-jetson-nano-120-fps-320x240","text":"Item Link Price NVIDIA Jetson Nano Development Kit https://amazon.com/dp/B07PZHBDKT $98.95 Arducam 5* https://amazon.com/dp/B012V1HEP4 $12.99 16GB MicroSD Card https://amazon.com/dp/B073K14CVB $5.79 HOMREE DC 12V to DC 5V (Micro USB) https://amazon.com/dp/B01MEESLZ6 $9.99 Total $127.72 * Yes, cameras for Raspberry Pi work on the Jetson Nano","title":"NVIDIA Jetson Nano 120+ FPS @ 320x240*"},{"location":"quickstart/hardware/#general-setup","text":"To connect any coprocessor to the robot, you will need an Ethernet cable . Plug the Ethernet cable into the extra port on the radio to connect your coprocessor to the robot.","title":"General Setup"},{"location":"quickstart/hardware/#using-a-pi-cam","text":"If you are using a Pi Cam (such as the Arducam 5) you will need to connect your Pi Cam to the port boxed in PURPLE on the image. Do not connect it to the port boxed in BLUE on the image.","title":"Using a Pi Cam"},{"location":"quickstart/hardware/#leds","text":"You can control LEDs either directly from the robot using the PCM, or by using GPIO (GPIO module coming soon).","title":"LEDs"},{"location":"quickstart/hardware/#pcm","text":"If you want to use PCM, make sure your PCM is running 12V, not 24V . Once you plug your LEDs into the PCM, you can control them from the Robot Code in the same way you would control a regular solenoid ( Java / C++ ).","title":"PCM"},{"location":"quickstart/hardware/#gpio","text":"If you plan on using GPIO, you will need a relay switch of some sort. Keep in mind that the Raspberry Pi's GPIO only outputs 3.3V. Here is a relay switch which has been successfully tested with a Raspberry Pi 4. Also, most LEDs run off of 12V. Here is a diagram of how to properly set up LED control from the Pi. Here is a diagram of how to properly set this up:","title":"GPIO"},{"location":"quickstart/installation/","text":"Depending on what system you are trying to install on, the process may differ. If you are installing on Raspberry Pi, go to the appropriate section . If you are trying to install OpenSight on a different coprocessor, such as the Jetson Nano, you can find the process here . Currently, OpenSight is only directly supported on Linux. It should still work on Windows or MacOS, however the process to do so is far too elaborate to explain here (requries compiling multiple Python libraries). To install on any other Linux system, you can follow the other systems installation . Installing on Raspberry Pi \u00b6 Note This is only required on the first installation of the image. After that, you can use the upgrader in order to upgrade your installation. Any exceptions to this will be plainly noted on the releases page. Insert your Raspberry Pi's Micro SD card into your computer. Please note that you need a Micro SD card with at least 4GB. All data on the SD card will be erased during the installation process . Download the latest Raspberry Pi image file from the releases page . Install a disk imaging software. The simplest imaging software is balenaEtcher . Click \"Select an Image\" and select the .zip file image you downloaded in step 1. For the drive, select your Micro SD card. Click \"Flash\". After this finishes, you can put your Micro SD card back into your Pi. OpenSight should now be running! You can continue to the Getting Started page. If you have any issues, please join our Discord , let us know the issue in the #help channel and we'll help you troubleshoot. Installing on Debian ARM systems \u00b6 You must install Debian on your coprocessor in order to continue with this section. If you are running a Debian ARM based system, you can use the same packages generated for the Raspberry Pi. If the output of dpkg-architecture -q DEB_BUILD_ARCH is armhf , you can use the following set of instructions. Types of systems that meet this requirement would be: Raspberry Pi (without erasing anything on your current Raspbian installation) Jetson Nano Many coprocessors Here are the differences between using the packages and installing with the regular Linux script: Automatic startup Installed system-wide Can use the upgrader Run these commands to do so: sudo apt update sudo apt install -y curl git jq mkdir /tmp/opsi ; cd /tmp/opsi url = \" $( curl https://api.github.com/repos/opensight-cv/packages/releases/latest | jq -r '.[\"assets\"][][\"browser_download_url\"]' | grep -v with ) \" curl -LO $url mkdir -p packages tar xf opsi-packages-*.tar.gz -C packages sudo apt install -y ./packages/deps/*.deb rm -rf /tmp/opsi/ reboot Once your coprocessor restats, OpenSight should now be running! You can continue to the Getting Started page. Installing on other systems \u00b6 If you are running a non-Debian derivative system (eg. anything other than Debian, Ubuntu, or Mint), you will need to install your distribution's version of the following: build-essential git curl python3.7 python3-dev python3.7-dev python3-pip python3-venv Once you have done this, or if you are running a Debian derivative, simply run this command to create an OpenSight instance in your current directory: curl -O https://opensight-cv.github.io/install-opsi.sh chmod +x install-opsi.sh ./install-opsi.sh or curl https://opensight-cv.github.io/install-opsi.sh | bash After you do so, you should be able to cd into the opensight folder and run the script: ./run.sh . Warning Please only run the one line command if you understand the security implications of it. We recommend you inspect the installation script to ensure it is safe.","title":"Installation"},{"location":"quickstart/installation/#installing-on-raspberry-pi","text":"Note This is only required on the first installation of the image. After that, you can use the upgrader in order to upgrade your installation. Any exceptions to this will be plainly noted on the releases page. Insert your Raspberry Pi's Micro SD card into your computer. Please note that you need a Micro SD card with at least 4GB. All data on the SD card will be erased during the installation process . Download the latest Raspberry Pi image file from the releases page . Install a disk imaging software. The simplest imaging software is balenaEtcher . Click \"Select an Image\" and select the .zip file image you downloaded in step 1. For the drive, select your Micro SD card. Click \"Flash\". After this finishes, you can put your Micro SD card back into your Pi. OpenSight should now be running! You can continue to the Getting Started page. If you have any issues, please join our Discord , let us know the issue in the #help channel and we'll help you troubleshoot.","title":"Installing on Raspberry Pi"},{"location":"quickstart/installation/#installing-on-debian-arm-systems","text":"You must install Debian on your coprocessor in order to continue with this section. If you are running a Debian ARM based system, you can use the same packages generated for the Raspberry Pi. If the output of dpkg-architecture -q DEB_BUILD_ARCH is armhf , you can use the following set of instructions. Types of systems that meet this requirement would be: Raspberry Pi (without erasing anything on your current Raspbian installation) Jetson Nano Many coprocessors Here are the differences between using the packages and installing with the regular Linux script: Automatic startup Installed system-wide Can use the upgrader Run these commands to do so: sudo apt update sudo apt install -y curl git jq mkdir /tmp/opsi ; cd /tmp/opsi url = \" $( curl https://api.github.com/repos/opensight-cv/packages/releases/latest | jq -r '.[\"assets\"][][\"browser_download_url\"]' | grep -v with ) \" curl -LO $url mkdir -p packages tar xf opsi-packages-*.tar.gz -C packages sudo apt install -y ./packages/deps/*.deb rm -rf /tmp/opsi/ reboot Once your coprocessor restats, OpenSight should now be running! You can continue to the Getting Started page.","title":"Installing on Debian ARM systems"},{"location":"quickstart/installation/#installing-on-other-systems","text":"If you are running a non-Debian derivative system (eg. anything other than Debian, Ubuntu, or Mint), you will need to install your distribution's version of the following: build-essential git curl python3.7 python3-dev python3.7-dev python3-pip python3-venv Once you have done this, or if you are running a Debian derivative, simply run this command to create an OpenSight instance in your current directory: curl -O https://opensight-cv.github.io/install-opsi.sh chmod +x install-opsi.sh ./install-opsi.sh or curl https://opensight-cv.github.io/install-opsi.sh | bash After you do so, you should be able to cd into the opensight folder and run the script: ./run.sh . Warning Please only run the one line command if you understand the security implications of it. We recommend you inspect the installation script to ensure it is safe.","title":"Installing on other systems"},{"location":"quickstart/upgrading/","text":"Depending on which version of OpenSight you are using, you may or may not be able to use the upgrader. If you installed using the Raspberry Pi image or the Debian ARM systems (packages) method you are able to use the upgrader. The current version number is viewable in the bottom left of the settings page. Upgrading on Raspberry Pi \u00b6 If you are on Raspberry Pi, you can do the following to update your OpenSight installation: Download the with dependencies tar.gz file on the latest release page from the packages repository. Go to the settings page OpenSight instance. Drag and drop the file into the \"Update\" box, or browse and select the file. Click the \"Update\" button. Your Raspberry Pi should now start updating. This may take multiple minutes. Once you are able to access OpenSight again, updating should be finished. If OpenSight is not accessible after approximately 10 minutes, either reflash the image or join our Discord for support. Info Technical Implications : The with dependencies tar.gz file contains updates for system packages as well the OpenSight packages. This ensures that any dependencies of OpenSight are upgraded along with OpenSight, and no manual upgrading is required. Upgrading on other Debian systems \u00b6 If you are on a different ARM Debian system, you can do the following to update your OpenSight installation: Download the normal tar.gz file (eg. not the with-dependencies file) on the latest release page from the packages repository. Go to the settings page OpenSight instance. Drag and drop the file into the \"Update\" box, or browse and select the file. Click the \"Update\" button. If OpenSight is not accessible after approximately 10 minutes, either reinstall OpenSight manually or join our Discord for support.","title":"Upgrading"},{"location":"quickstart/upgrading/#upgrading-on-raspberry-pi","text":"If you are on Raspberry Pi, you can do the following to update your OpenSight installation: Download the with dependencies tar.gz file on the latest release page from the packages repository. Go to the settings page OpenSight instance. Drag and drop the file into the \"Update\" box, or browse and select the file. Click the \"Update\" button. Your Raspberry Pi should now start updating. This may take multiple minutes. Once you are able to access OpenSight again, updating should be finished. If OpenSight is not accessible after approximately 10 minutes, either reflash the image or join our Discord for support. Info Technical Implications : The with dependencies tar.gz file contains updates for system packages as well the OpenSight packages. This ensures that any dependencies of OpenSight are upgraded along with OpenSight, and no manual upgrading is required.","title":"Upgrading on Raspberry Pi"},{"location":"quickstart/upgrading/#upgrading-on-other-debian-systems","text":"If you are on a different ARM Debian system, you can do the following to update your OpenSight installation: Download the normal tar.gz file (eg. not the with-dependencies file) on the latest release page from the packages repository. Go to the settings page OpenSight instance. Drag and drop the file into the \"Update\" box, or browse and select the file. Click the \"Update\" button. If OpenSight is not accessible after approximately 10 minutes, either reinstall OpenSight manually or join our Discord for support.","title":"Upgrading on other Debian systems"}]}